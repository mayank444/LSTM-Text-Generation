{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayankpara/deep-learning/blob/main/Text-Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjI4L6saLFRe"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bofg3uug_pVg"
      },
      "source": [
        "import keras\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iT4Wqa4_0XW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3fc681-9226-4e89-8de7-6b0e427015fa"
      },
      "source": [
        "# load data\r\n",
        "path = keras.utils.get_file('nietzsche.txt',origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyu6xIQBA6lQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8c0c3a-353f-42ff-c6a0-b93034a09a1e"
      },
      "source": [
        "# open data\r\n",
        "text = open(path).read().lower()\r\n",
        "print('corpus length:',len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdTZSsV_LfSq"
      },
      "source": [
        "# Vectorizing **data** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JdEldyPBEGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe05be5-7575-4a36-8b8b-ec8a141603ea"
      },
      "source": [
        "# vectorizing sequences of data\r\n",
        "maxlen = 60\r\n",
        "step = 3\r\n",
        "sentences = []\r\n",
        "next_chars = []\r\n",
        "for i in range(0,len(text)-maxlen,step):\r\n",
        "  sentences.append(text[i:i+maxlen])\r\n",
        "  next_chars.append(text[i+maxlen])\r\n",
        "print('number of sequences:',len(sentences))\r\n",
        "chars = sorted(list(set(text)))\r\n",
        "char_indices = dict((char,chars.index(char)) for char in chars)\r\n",
        "x = np.zeros((len(sentences),maxlen,len(chars)),dtype=np.bool)\r\n",
        "y = np.zeros((len(sentences),len(chars)),dtype=np.bool)\r\n",
        "for i,sentence in enumerate(sentences):\r\n",
        "  for t,char in enumerate(sentence):\r\n",
        "    x[i,t,char_indices[char]] = 1\r\n",
        "  y[i,char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of sequences: 200278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQv3YHNZB_72"
      },
      "source": [
        "# single layer LSTM model\r\n",
        "model = keras.models.Sequential([\r\n",
        "                                 keras.layers.LSTM(128,input_shape=(maxlen,len(chars))),\r\n",
        "                                 keras.layers.Dense(len(chars),activation='softmax')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAcYyd4yGyKn"
      },
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\r\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFcV51nBHJ0y"
      },
      "source": [
        "# function to sample next character\r\n",
        "def sample(preds,temperature=1.0):\r\n",
        "  preds = np.asarray(preds).astype('float64')\r\n",
        "  preds = np.log(preds)/temperature\r\n",
        "  exp_preds = np.exp(preds)\r\n",
        "  preds = exp_preds/np.sum(exp_preds)\r\n",
        "  probas = np.random.multinomial(1,preds,1)\r\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgZSzjIOL5H1"
      },
      "source": [
        "# Text generation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rn3c3kvadVH"
      },
      "source": [
        "import sys\r\n",
        "import random\r\n",
        "\r\n",
        "for epoch in range(1,60):\r\n",
        "  print('epoch',epoch)\r\n",
        "  # fit the model for 1 iteration\r\n",
        "  model.fit(x,y, batch_size=128, epochs=1)\r\n",
        "  start_index = random.randint(0,len(text)-maxlen-1)\r\n",
        "  generated_text = text[start_index: start_index+maxlen]\r\n",
        "  print('---Generated with seed: \"' + generated_text + '\"')\r\n",
        "\r\n",
        "\r\n",
        "  # for different temperatures\r\n",
        "  for temperature in [0.2,0.5,1.0,1.2]:\r\n",
        "    print('temperature: ',temperature)\r\n",
        "    sys.stdout.write(generated_text)\r\n",
        "    for i in range(400):\r\n",
        "      sampled = np.zeros((1,maxlen,len(chars)))\r\n",
        "      for t,char in enumerate(generated_text):\r\n",
        "        sampled[0,t,char_indices[char]] = 1.\r\n",
        "      \r\n",
        "      preds = model.predict(sampled,verbose=0)[0]\r\n",
        "      next_index = sample(preds,temperature)\r\n",
        "      next_char = chars[next_index]\r\n",
        "\r\n",
        "      generated_text += next_char\r\n",
        "      generated_text = generated_text[1:]\r\n",
        "      sys.stdout.write(next_char)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUI0fXVjMKST"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
